{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "the_office.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from types import SimpleNamespace\n",
        "from collections import Counter\n",
        "import os\n",
        "import re\n",
        "import pathlib\n",
        "import array\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.275144Z",
          "iopub.execute_input": "2022-03-22T14:47:46.275476Z",
          "iopub.status.idle": "2022-03-22T14:47:46.282030Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.275437Z",
          "shell.execute_reply": "2022-03-22T14:47:46.281208Z"
        },
        "trusted": true,
        "id": "1ottVuubKern"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('dataset.txt', 'r')\n",
        "readfile = f.readlines()\n",
        "dataset = [x for x in readfile if '\\n' != x or '<EOE>' != x]\n",
        "dataset = np.array(dataset)\n",
        "print(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.333629Z",
          "iopub.execute_input": "2022-03-22T14:47:46.333864Z",
          "iopub.status.idle": "2022-03-22T14:47:46.492133Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.333836Z",
          "shell.execute_reply": "2022-03-22T14:47:46.491395Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "XGPFe82uKers",
        "outputId": "78298d3c-a919-4bdf-af36-d54f0cad1968"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fe094d77dc1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreadfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreadfile\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'<EOE>'\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.493747Z",
          "iopub.execute_input": "2022-03-22T14:47:46.494477Z",
          "iopub.status.idle": "2022-03-22T14:47:46.500119Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.494441Z",
          "shell.execute_reply": "2022-03-22T14:47:46.499382Z"
        },
        "trusted": true,
        "id": "L0HWcYHaKert"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(dataset):\n",
        "  \"\"\"\n",
        "  :param dataset: array of sentences delimited by /n.\n",
        "  :return: array of sentences with the symbols tokenized.\n",
        "  \"\"\"\n",
        "  punct={\n",
        "          '.':\" ||period|| \",\n",
        "          \",\":\" ||comma|| \",\n",
        "          '\"':\" ||doublequotationmark|| \",\n",
        "          \"'\":\" ||quotationmark|| \",\n",
        "          \"?\":\" ||questionmark|| \",\n",
        "          \"-\":\" ||dash|| \",\n",
        "          \"\\n\":\" ||return||\",\n",
        "          \")\":\" ||rightparentheses|| \",\n",
        "          \"(\":\" ||leftparentheses|| \",\n",
        "          \"[\":\" ||leftbracket|| \",\n",
        "          \"]\":\" ||rightbracket|| \",\n",
        "          \";\":\" ||semicolon|| \",\n",
        "          \"!\":\" ||exclamationmark|| \",\n",
        "          \":\": \" ||colon|| \",\n",
        "          \"%\":\" ||percent|| \",\n",
        "          \"$\":\" ||dollar|| \",\n",
        "          \"#\":\" ||hashtag|| \",\n",
        "          \"/\":\" ||forwardbar|| \"\n",
        "      }\n",
        "\n",
        "  new_dataset = []\n",
        "  for sentence in dataset:\n",
        "    sentence = sentence.replace('.', punct['.'])\n",
        "    sentence = sentence.replace(',', punct[','])\n",
        "    sentence = sentence.replace('\"', punct['\"'])\n",
        "    sentence = sentence.replace(\"'\", punct[\"'\"])\n",
        "    sentence = sentence.replace('?', punct['?'])\n",
        "    sentence = sentence.replace('-', punct['-'])\n",
        "    sentence = sentence.replace('\\n', punct['\\n'])\n",
        "    sentence = sentence.replace(')', punct[')'])\n",
        "    sentence = sentence.replace('(', punct['('])\n",
        "    sentence = sentence.replace('[', punct['['])\n",
        "    sentence = sentence.replace(']', punct[']'])\n",
        "    sentence = sentence.replace(';', punct[';'])\n",
        "    sentence = sentence.replace('!', punct['!'])\n",
        "    sentence = sentence.replace(':', punct[':'])\n",
        "    sentence = sentence.replace('%', punct['%'])\n",
        "    sentence = sentence.replace('$', punct['$'])\n",
        "    sentence = sentence.replace('#', punct['#'])\n",
        "    sentence = sentence.replace('/', punct['/'])\n",
        "    new_dataset += sentence.split(\" \")\n",
        "  return np.array(new_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.501467Z",
          "iopub.execute_input": "2022-03-22T14:47:46.502066Z",
          "iopub.status.idle": "2022-03-22T14:47:46.517848Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.502028Z",
          "shell.execute_reply": "2022-03-22T14:47:46.516995Z"
        },
        "trusted": true,
        "id": "dds89VKBKeru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vocab(text):\n",
        "  \"\"\"\n",
        "  :param text: text split into sentences delimited by /n.\n",
        "  :return: an np array with unique strings, the vocabulary of the dataset.\n",
        "  \"\"\"\n",
        "  vocab = np.unique(text)\n",
        "  return vocab"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.559597Z",
          "iopub.execute_input": "2022-03-22T14:47:46.560006Z",
          "iopub.status.idle": "2022-03-22T14:47:46.567416Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.559970Z",
          "shell.execute_reply": "2022-03-22T14:47:46.566711Z"
        },
        "trusted": true,
        "id": "e9LXHI61Kerv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param text: The text of tv scripts split into words\n",
        "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    word_counts=Counter(text)\n",
        "    sorted_vocab=sorted(word_counts,key=word_counts.get,reverse=True)\n",
        "\n",
        "    texti=set(text)\n",
        "    vocab_to_int={word:ii for ii,word in enumerate(texti,0)}\n",
        "    int_to_vocab={items:key for key,items in vocab_to_int.items()}\n",
        "\n",
        "    return (vocab_to_int, int_to_vocab)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.618375Z",
          "iopub.execute_input": "2022-03-22T14:47:46.619664Z",
          "iopub.status.idle": "2022-03-22T14:47:46.626378Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.619626Z",
          "shell.execute_reply": "2022-03-22T14:47:46.625411Z"
        },
        "trusted": true,
        "id": "Y3Nx4CmkKerw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_int(text, vocab_to_int):\n",
        "  s = pd.Series(text)\n",
        "  s = s.map(vocab_to_int)\n",
        "  return s.to_numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.691035Z",
          "iopub.execute_input": "2022-03-22T14:47:46.691272Z",
          "iopub.status.idle": "2022-03-22T14:47:46.695708Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.691242Z",
          "shell.execute_reply": "2022-03-22T14:47:46.695031Z"
        },
        "trusted": true,
        "id": "bN6sLdsfKerw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(int_text, int_to_vocab):\n",
        "  s = pd.Series(int_text)\n",
        "  s = s.map(int_to_vocab)\n",
        "  return s.to_numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.759108Z",
          "iopub.execute_input": "2022-03-22T14:47:46.759319Z",
          "iopub.status.idle": "2022-03-22T14:47:46.763735Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.759294Z",
          "shell.execute_reply": "2022-03-22T14:47:46.762853Z"
        },
        "trusted": true,
        "id": "ZhNK1MxlKery"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(train_data):\n",
        "    col_type = train_data[0].dtype\n",
        "\n",
        "    if col_type != object:\n",
        "        c_min = train_data.min()\n",
        "        c_max = train_data.max()\n",
        "        if str(col_type)[:3] == 'int':\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                train_data = train_data.astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                train_data = train_data.astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                train_data = train_data.astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                train_data = train_data.astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                train_data = train_data.astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                train_data = train_data.astype(np.float32)\n",
        "            else:\n",
        "                train_data = train_data.astype(np.float64)\n",
        "    else:\n",
        "        train_data = train_data.astype('category')\n",
        "    print(train_data[0].dtype)\n",
        "    return train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.812959Z",
          "iopub.execute_input": "2022-03-22T14:47:46.813365Z",
          "iopub.status.idle": "2022-03-22T14:47:46.823068Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.813332Z",
          "shell.execute_reply": "2022-03-22T14:47:46.822198Z"
        },
        "trusted": true,
        "id": "LikY7n7EKery"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenize(dataset)\n",
        "vocabulary = vocab(tokenized_text)\n",
        "vocab_to_int, int_to_vocab = create_lookup_tables(vocabulary)\n",
        "int_text = text_to_int(tokenized_text, vocab_to_int)\n",
        "#int_text = reduce_mem_usage(int_text)\n",
        "\n",
        "del dataset\n",
        "del tokenized_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:46.867066Z",
          "iopub.execute_input": "2022-03-22T14:47:46.867248Z",
          "iopub.status.idle": "2022-03-22T14:47:47.780508Z",
          "shell.execute_reply.started": "2022-03-22T14:47:46.867226Z",
          "shell.execute_reply": "2022-03-22T14:47:47.779788Z"
        },
        "trusted": true,
        "id": "0szaZgt_Kerz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(int_text.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:47.781972Z",
          "iopub.execute_input": "2022-03-22T14:47:47.782780Z",
          "iopub.status.idle": "2022-03-22T14:47:47.789537Z",
          "shell.execute_reply.started": "2022-03-22T14:47:47.782741Z",
          "shell.execute_reply": "2022-03-22T14:47:47.788654Z"
        },
        "trusted": true,
        "id": "ZOXxOL24Ker0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"WARNING: Training without GPU can be very slow!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:47.791133Z",
          "iopub.execute_input": "2022-03-22T14:47:47.791559Z",
          "iopub.status.idle": "2022-03-22T14:47:47.796792Z",
          "shell.execute_reply.started": "2022-03-22T14:47:47.791461Z",
          "shell.execute_reply": "2022-03-22T14:47:47.795974Z"
        },
        "trusted": true,
        "id": "MYOSTQM5Ker0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def batch_data(words, sequence_length, batch_size):\n",
        "    \"\"\"\n",
        "    Batch the neural network data using DataLoader\n",
        "    :param words: The word ids of the TV scripts\n",
        "    :param sequence_length: The sequence length of each batch\n",
        "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
        "    :return: DataLoader with batched data\n",
        "    \"\"\"\n",
        "    feature_tensors = []\n",
        "    target_tensors = []\n",
        "    for i in range(len(words)):\n",
        "      target_idx = i + sequence_length\n",
        "      if target_idx < len(words):\n",
        "        features = words[i:i + sequence_length]\n",
        "        feature_tensors.append(features)\n",
        "\n",
        "        target = words[target_idx]\n",
        "        target_tensors.append(target)\n",
        "        \n",
        "    data = TensorDataset(torch.from_numpy(np.array(feature_tensors)).to(device), torch.from_numpy(np.array(target_tensors)).to(device))\n",
        "    data_loader = torch.utils.data.DataLoader(data, shuffle=False, batch_size=batch_size)\n",
        "    # return a dataloader\n",
        "      \n",
        "    return data_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:47.799162Z",
          "iopub.execute_input": "2022-03-22T14:47:47.799631Z",
          "iopub.status.idle": "2022-03-22T14:47:47.807476Z",
          "shell.execute_reply.started": "2022-03-22T14:47:47.799595Z",
          "shell.execute_reply": "2022-03-22T14:47:47.806440Z"
        },
        "trusted": true,
        "id": "2BloWTfsKer1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / math.sqrt(d_k)\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ],
      "metadata": {
        "id": "AzrWFqBSKsY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Data params '''\n",
        "# Sequence Length\n",
        "sequence_length = 5   # of words in a sequence\n",
        "# Batch Size\n",
        "batch_size = 300\n",
        "\n",
        "# data loader - do not change\n",
        "train_loader = batch_data(int_text, sequence_length, batch_size)\n",
        "\n",
        "'''Training parameters'''\n",
        "# Number of Epochs\n",
        "num_epochs = 3\n",
        "# Learning Rate\n",
        "learning_rate = 0.0008\n",
        "\n",
        "'''Model parameters'''\n",
        "# Vocab size\n",
        "vocab_size = len(vocabulary)\n",
        "# Output size\n",
        "output_size = vocab_size\n",
        "# Embedding Dimension\n",
        "embedding_dim = 200\n",
        "# Hidden Dimension\n",
        "hidden_dim = 200\n",
        "# Number of RNN Layers\n",
        "n_layers = 3\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 20\n",
        "print(vocab_size)\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:47.837645Z",
          "iopub.execute_input": "2022-03-22T14:47:47.837891Z",
          "iopub.status.idle": "2022-03-22T14:47:48.648381Z",
          "shell.execute_reply.started": "2022-03-22T14:47:47.837860Z",
          "shell.execute_reply": "2022-03-22T14:47:48.647589Z"
        },
        "trusted": true,
        "id": "e7ol1dCmKer2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, bias=True):\n",
        "        super().__init__()\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Empirically observed the convergence to be much better with the scaled initialization\n",
        "        nn.init.xavier_uniform_(self.k_proj.weight, gain=1 / math.sqrt(2))\n",
        "        nn.init.xavier_uniform_(self.v_proj.weight, gain=1 / math.sqrt(2))\n",
        "        nn.init.xavier_uniform_(self.q_proj.weight, gain=1 / math.sqrt(2))\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        if self.out_proj.bias is not None:\n",
        "            nn.init.constant_(self.out_proj.bias, 0.)\n",
        "\n",
        "    # B = Batch size\n",
        "    # W = Number of context words (left + right)\n",
        "    # E = embedding_dim\n",
        "    def forward(self, x):\n",
        "        # x shape is (B, W, E)\n",
        "        q = self.q_proj(x)\n",
        "        # q shape is (B, W, E)\n",
        "        k = self.k_proj(x)\n",
        "        # k shape is (B, W, E)\n",
        "        v = self.v_proj(x)\n",
        "        # k shape is (B, W, E)\n",
        "        y, _ = attention(q, k, v)\n",
        "        # y shape is (B, W, E)\n",
        "        y = self.out_proj(y)\n",
        "        # y shape is (B, W, E)\n",
        "        return y\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:47.808900Z",
          "iopub.execute_input": "2022-03-22T14:47:47.809179Z",
          "iopub.status.idle": "2022-03-22T14:47:47.824824Z",
          "shell.execute_reply.started": "2022-03-22T14:47:47.809145Z",
          "shell.execute_reply": "2022-03-22T14:47:47.823866Z"
        },
        "trusted": true,
        "id": "3nHLU5zwKer1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, dim_feedforward=512, dropout=0.1, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.self_attn = SelfAttention(d_model)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src2 = self.self_attn(src)\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src"
      ],
      "metadata": {
        "id": "KbYlsn3VK8wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Predictor(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim, context_words=sequence_length):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
        "        self.lin = nn.Linear(embedding_dim, num_embeddings, bias=False)\n",
        "        self.att = TransformerLayer(embedding_dim)\n",
        "        self.position_embedding = nn.Parameter(torch.Tensor(context_words, embedding_dim))\n",
        "        nn.init.xavier_uniform_(self.position_embedding)\n",
        "\n",
        "    # B = Batch size\n",
        "    # W = Number of context words (left + right)\n",
        "    # E = embedding_dim\n",
        "    # V = num_embeddings (number of words)\n",
        "    def forward(self, input):\n",
        "        # input shape is (B, W)\n",
        "        e = self.emb(input)\n",
        "        # e shape is (B, W, E)\n",
        "        u = e + self.position_embedding\n",
        "        # u shape is (B, W, E)\n",
        "        v = self.att(u)\n",
        "        # v shape is (B, W, E)\n",
        "        x = v.sum(dim=1)\n",
        "        # x shape is (B, E)\n",
        "        y = self.lin(x)\n",
        "        # y shape is (B, V)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "qz5v7s9FLCE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Predictor(len(vocabulary), embedding_dim).to(device)"
      ],
      "metadata": {
        "id": "utRJ4TdkLF4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, n_epochs, device, show_every_n_batches=100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    ncorrect = 0\n",
        "    ntokens = 0\n",
        "    niterations = 0\n",
        "    for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "      n_batches = len(train_loader.dataset)//batch_size\n",
        "      if(batch_i > n_batches):\n",
        "        break\n",
        "      model.zero_grad()\n",
        "\n",
        "      output = model(inputs)\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Training statistics\n",
        "      total_loss += loss.item()\n",
        "      ncorrect += (torch.max(output, 1)[1] == labels).sum().item()\n",
        "      ntokens += labels.numel()\n",
        "      niterations += 1\n",
        "      if niterations == 200 or niterations == 500 or niterations % 1000 == 0:\n",
        "          print(f'Train: wpb={ntokens//niterations}, num_updates={niterations}, accuracy={100*ncorrect/ntokens:.1f}, loss={total_loss/ntokens:.2f}')\n",
        "\n",
        "    total_loss = total_loss / ntokens\n",
        "    accuracy = 100 * ncorrect / ntokens\n",
        "\n",
        "    return accuracy, total_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:47:48.650596Z",
          "iopub.execute_input": "2022-03-22T14:47:48.651039Z",
          "iopub.status.idle": "2022-03-22T14:47:48.659417Z",
          "shell.execute_reply.started": "2022-03-22T14:47:48.651000Z",
          "shell.execute_reply": "2022-03-22T14:47:48.658696Z"
        },
        "trusted": true,
        "id": "EnwnPOwwKer3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "train_accuracy = []\n",
        "wiki_accuracy = []\n",
        "valid_accuracy = []\n",
        "for epoch_i in range(1, num_epochs + 1):\n",
        "    acc, loss = train(model, criterion, optimizer, device, show_every_n_batches)\n",
        "    train_accuracy.append(acc)\n",
        "    print(f'| epoch {epoch_i:03d} | train accuracy={acc:.1f}%, train loss={loss:.2f}')\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'the_office_scripts')\n",
        "print('Model Trained and Saved')"
      ],
      "metadata": {
        "id": "lI21MUmhLpO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(model, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
        "    \"\"\"\n",
        "    Generate text using the neural network\n",
        "    :param decoder: The PyTorch Module that holds the trained neural network\n",
        "    :param prime_id: The word id to start the first prediction\n",
        "    :param int_to_vocab: Dict of word id keys to word values\n",
        "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
        "    :param pad_value: The value used to pad a sequence\n",
        "    :param predict_len: The length of text to generate\n",
        "    :return: The generated text\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # create a sequence (batch_size=1) with the prime_id\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        \n",
        "        \n",
        "        # get the output of the rnn\n",
        "        current_seq= torch.tensor(current_seq).to(device)\n",
        "        output = model(current_seq)\n",
        "\n",
        "        # get the next word probabilities\n",
        "        p = F.softmax(output, dim=1).data\n",
        "\n",
        "        # use top_k sampling to get the index of the next word\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.cpu().detach().numpy().squeeze()\n",
        "\n",
        "        # select the likely next word index with some element of randomness\n",
        "        p = p.cpu().detach().numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        \n",
        "        # retrieve that word from the dictionary\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "        \n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = np.roll(current_seq.cpu().detach().numpy(), -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    # Replace punctuation tokens\n",
        "    for key, token in token_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    gen_sentences = gen_sentences.replace('  ', ' ')\n",
        "    \n",
        "    # return all the sentences\n",
        "    return gen_sentences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:58:12.428398Z",
          "iopub.execute_input": "2022-03-22T14:58:12.429116Z",
          "iopub.status.idle": "2022-03-22T14:58:12.441409Z",
          "shell.execute_reply.started": "2022-03-22T14:58:12.429075Z",
          "shell.execute_reply": "2022-03-22T14:58:12.440569Z"
        },
        "trusted": true,
        "id": "geYLlRbqKer4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_length = 1000 # modify the length to your preference\n",
        "prime_word = 'Holly' # name for starting the script\n",
        "\n",
        "token_dict= {\n",
        "          '.':\"||period||\",\n",
        "          \",\":\"||comma||\",\n",
        "          '\"':\"||doublequotationmark||\",\n",
        "          \"'\":\"||quotationmark||\",\n",
        "          \"?\":\"||questionmark||\",\n",
        "          \"-\":\"||dash||\",\n",
        "          \"\\n\":\"||return||\",\n",
        "          \")\":\"||rightparentheses||\",\n",
        "          \"(\":\"||leftparentheses||\",\n",
        "          \"[\":\"||leftbracket||\",\n",
        "          \"]\":\"||rightbracket||\",\n",
        "          \";\":\"||semicolon||\",\n",
        "          \"!\":\"||exclamationmark||\",\n",
        "          \":\": \"||colon||\",\n",
        "          \"%\":\"||percent||\",\n",
        "          \"$\":\"||dollar||\",\n",
        "          \"#\":\"||hashtag||\",\n",
        "          \"/\":\"||forwardbar||\"\n",
        "      }\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "pad_word= '||return||'\n",
        "generated_script = generate(model, vocab_to_int[prime_word], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
        "print(generated_script)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-22T14:58:12.442583Z",
          "iopub.execute_input": "2022-03-22T14:58:12.443158Z",
          "iopub.status.idle": "2022-03-22T14:58:15.778791Z",
          "shell.execute_reply.started": "2022-03-22T14:58:12.443122Z",
          "shell.execute_reply": "2022-03-22T14:58:15.777961Z"
        },
        "trusted": true,
        "id": "pqKh0ZjlKer4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}